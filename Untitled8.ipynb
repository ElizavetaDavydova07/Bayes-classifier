{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                           sms_text\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1   ham  U dun say so early hor... U c already then say...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'C:/Users/Лиза/Downloads/sms_spam_collection.tar.gz'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filename,\n",
    "    compression='gzip',\n",
    "    header=1,\n",
    "    sep='\\t',\n",
    "    encoding='utf8',\n",
    "    names=['class', 'sms_text'],\n",
    "    error_bad_lines=False\n",
    ")\n",
    "\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5571 2\n"
     ]
    }
   ],
   "source": [
    "num_objects, num_features = df.shape\n",
    "print(num_objects, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    spam\n",
       "1     ham\n",
       "2     ham\n",
       "3    spam\n",
       "4     ham\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2       False\n",
       "3        True\n",
       "4       False\n",
       "        ...  \n",
       "5566    False\n",
       "5567    False\n",
       "5568    False\n",
       "5569    False\n",
       "5570    False\n",
       "Name: class, Length: 5571, dtype: bool"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPAM_CLASS = 'spam'\n",
    "NOT_SPAM_CLASS = 'ham'\n",
    "\n",
    "df['class'] == SPAM_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam sms: 747, not spam sms 4823\n"
     ]
    }
   ],
   "source": [
    "spam_sms_num = (df['class'] == SPAM_CLASS).sum()\n",
    "notspam_sms_num = (df['class'] == NOT_SPAM_CLASS).sum()\n",
    "\n",
    "print(f'spam sms: {spam_sms_num}, not spam sms {notspam_sms_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1341, 0.8657\n"
     ]
    }
   ],
   "source": [
    "p_spam = spam_sms_num/num_objects\n",
    "\n",
    "# априорная вероятность класса не спам\n",
    "p_notspam = notspam_sms_num/num_objects\n",
    "\n",
    "print(f'{p_spam:.4f}, {p_notspam:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_preprocess(sms_text: str) -> str:\n",
    "    \"\"\"Преобразование текста для анализа\"\"\"\n",
    "    \n",
    "    text_no_punctuation = ''.join([char\n",
    "        for char in sms_text\n",
    "        if char not in string.punctuation])\n",
    "    text_lowercase = ' '.join([\n",
    "        word.lower()\n",
    "        for word in text_no_punctuation.split(sep=' ')\n",
    "    ])\n",
    "    \n",
    "    return text_lowercase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text: str):\n",
    "    tokens = []\n",
    "    #processed_text = text_preprocess(text)\n",
    "    tokens = text.split(' ')\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = df['sms_text'].tolist()\n",
    "s_tokenize = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-629f755f39a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0ms_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0ms_tokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_tokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-5ebb1b564cd7>\u001b[0m in \u001b[0;36mtext_preprocess\u001b[1;34m(sms_text)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Преобразование текста для анализа\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     text_no_punctuation = ''.join([char\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msms_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         if char not in string.punctuation])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "for s in all_text:\n",
    "    s_preprocessed = text_preprocess(s)\n",
    "    s_tokenize.append(tokenize_text(s_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
